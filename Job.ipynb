{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IxJs3dL1lKb",
        "outputId": "dd503411-f786-4606-92f4-ff230d8f043f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/434.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m430.1/434.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.1/434.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.22-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.55)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.24)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.31)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (2.33.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.22-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.22 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 typing-inspect-0.9.0\n",
            "Collecting assemblyai\n",
            "  Downloading assemblyai-0.39.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: httpx>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from assemblyai) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1.10.17 in /usr/local/lib/python3.11/dist-packages (from assemblyai) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7 in /usr/local/lib/python3.11/dist-packages (from assemblyai) (4.13.2)\n",
            "Requirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.11/dist-packages (from assemblyai) (15.0.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.19.0->assemblyai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.17->assemblyai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.17->assemblyai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.17->assemblyai) (0.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.19.0->assemblyai) (1.3.1)\n",
            "Downloading assemblyai-0.39.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: assemblyai\n",
            "Successfully installed assemblyai-0.39.1\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n",
            "Collecting streamlit-audiorecorder\n",
            "  Downloading streamlit_audiorecorder-0.0.6-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting streamlit>=0.63 (from streamlit-audiorecorder)\n",
            "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting pydub>=0.24 (from streamlit-audiorecorder)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit>=0.63->streamlit-audiorecorder)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit>=0.63->streamlit-audiorecorder)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (1.35.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-audiorecorder) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-audiorecorder) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-audiorecorder) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-audiorecorder) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-audiorecorder) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=0.63->streamlit-audiorecorder) (1.17.0)\n",
            "Downloading streamlit_audiorecorder-0.0.6-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.7/487.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, watchdog, pydeck, streamlit, streamlit-audiorecorder\n",
            "Successfully installed pydeck-0.9.1 pydub-0.25.1 streamlit-1.44.1 streamlit-audiorecorder-0.0.6 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU \"langchain[groq]\"\n",
        "!pip install -qU langchain-text-splitters\n",
        "!pip install -qU langchain-chroma\n",
        "!pip install -U langchain-community\n",
        "!pip install assemblyai\n",
        "!pip install python-docx\n",
        "!pip install streamlit-audiorecorder\n",
        "!pip install streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#key-grok =  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\n",
        "#key-huggingface = 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\n",
        "#assemblyai = cce30862c26442f09e577fbe639108ed"
      ],
      "metadata": {
        "id": "lG3nuFRS2lV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "from groq import Groq\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "model_name = 'all-MiniLM-L6-v2' # assign the model name to a variable\n",
        "\n",
        "# Create an embedding instance\n",
        "embedding = SentenceTransformerEmbeddings(model_name=model_name) # use model_name keyword argument\n",
        "\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"example_collection\",\n",
        "    embedding_function=embedding,\n",
        "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
        ")\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n",
        "if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")\n",
        "\n",
        "\n",
        "model = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")\n",
        "\n",
        "client = Groq()\n",
        "\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size=1000,  # Increased chunk size\n",
        "    chunk_overlap=50,  # Reduced chunk overlap\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create an embedding instance\n",
        "\n"
      ],
      "metadata": {
        "id": "PNqrkdJ-4bN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "b7437285-9f3e-425a-8b3a-c7473c2513c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-d94e9ef654a8>:17: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding = SentenceTransformerEmbeddings(model_name=model_name) # use model_name keyword argument\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import assemblyai as aai\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Set AssemblyAI API key (get from assembly.ai after signup)\n",
        "aai.settings.api_key = \"cce30862c26442f09e577fbe639108ed\"\n",
        "\n",
        "# Configure transcription with diarization\n",
        "config = aai.TranscriptionConfig(speaker_labels=True)\n",
        "transcriber = aai.Transcriber()\n",
        "\n",
        "# Transcribe audio file (local or URL)\n",
        "audio_file = \"audio.mp3\"  # Replace with your audio file\n",
        "transcript = transcriber.transcribe(audio_file, config=config)\n",
        "\n",
        "# Create LangChain Document with speaker-tagged text\n",
        "text_with_speakers = \"\"\n",
        "for utterance in transcript.utterances:\n",
        "    text_with_speakers += f\"Speaker {utterance.speaker} [{utterance.start/1000:.1f}s - {utterance.end/1000:.1f}s]: {utterance.text}\\n\"\n",
        "\n",
        "doc = Document(page_content=text_with_speakers)\n",
        "\n",
        "# Print the result\n",
        "print(doc.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2awYWOz1Sdin",
        "outputId": "a74d7612-f31e-457a-ad47-cbea34e65a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(transcript.utterances[40].text)\n",
        "temp=model.invoke(\"\"\"Perform sentiment ananlysis and\n",
        "Classify the following text on a scale of 1 to 10. 1 being bad and\n",
        "10 being the best. Give a 1 word answer: \"\"\"+transcript.utterances[29].text)\n",
        "print(temp.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq-yXE5HV5cX",
        "outputId": "02329f54-b1b5-42fe-a2ec-a6619755f09a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yeah, disappeared. Now username and password. It's asking.\n",
            "The text is: \"for tom, v for victor\"\n",
            "\n",
            "Sentiment Analysis:\n",
            "The text appears to be a cryptic message or a playful phrase, rather than an expression of opinion or emotion. It lacks contextual information and seems to be more of a clever play on words than a sentiment-bearing statement.\n",
            "\n",
            "Classification on a scale of 1 to 10:\n",
            "I would rate this text a 6 out of 10. The text is ambiguous and doesn't convey a strong emotional tone, but it does have a clever and creative quality to it.\n",
            "\n",
            "One-word answer:\n",
            "quirky\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from docx import Document\n",
        "\n",
        "def read_docx(file_path):\n",
        "    doc = Document(file_path)\n",
        "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "\n",
        "def read_all_docx_in_folder(folder_path):\n",
        "    all_texts = {}\n",
        "    for filename in os.listdir(folder_path):\n",
        "        print(filename)\n",
        "        if filename.endswith(\".docx\"):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            try:\n",
        "                text = read_docx(file_path)\n",
        "                all_texts[filename] = text\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to read {filename}: {e}\")\n",
        "    return all_texts\n",
        "\n",
        "folder_path = \"RagDocs\"\n",
        "documents = read_all_docx_in_folder(folder_path)\n",
        "\n",
        "for filename, content in documents.items():\n",
        "#    print(content)\n",
        "    state_of_the_union =content\n",
        "    texts = text_splitter.create_documents([state_of_the_union])\n",
        "    texts_content = [t.page_content for t in texts]\n",
        "    vector_store.add_texts(texts=texts_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1wfn-vAO-bb",
        "outputId": "79f09d66-b635-4671-92f6-7bcac52a6431",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K 10.docx\n",
            "SOP for IPTVNW.docx\n",
            "MAG 524w3.docx\n",
            "MAG 544w3.docx\n",
            "Z (1) RNDLT.docx\n",
            "Formuler Z4 z5.docx\n",
            "TV Plus pro TS.docx\n",
            "MAG 540.docx\n",
            "TVIP.docx\n",
            "K2 TS.docx\n",
            "MAG 540w3.docx\n",
            "SOPs for TIVI Mate.docx\n",
            "Buzz e1.docx\n",
            "k6 ts.docx\n",
            "Buzz TV.docx\n",
            "256 254 322.docx\n",
            "MAG 544.docx\n",
            "MAG 524.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I have a Stb issue how do i solve it\"\n",
        "results = vector_store.similarity_search(query, k=20)\n",
        "context=\" \"\n",
        "for r in results:\n",
        "    context=context+r.page_content\n",
        "#    print(f\"Match: {r.page_content}\")\n",
        "ans=model.invoke(\" Answer the question based on the following context:\"+ context+\"Answer the question based on the above context:\"+query)\n",
        "print(ans.content)\n",
        "#print(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gou9DSD4Kce",
        "outputId": "ef59c599-5ad1-456a-de46-518790fe2bdb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the context, here are some possible steps to solve your STB issue:\n",
            "\n",
            "1. **Try the basic settings first**: Before performing a factory reset, try checking the basic settings of your STB. Make sure it's connected to the internet, and that the power cable and HDMI cable are properly connected.\n",
            "2. **Check for software updates**: Ensure that your STB's software is up-to-date. You can check for updates by going to the Settings menu, then selecting \"System\" or \"Software Update\".\n",
            "3. **Perform a factory reset**: If the issue persists, you can try performing a factory reset. To do this, press the Home button, then go to Settings > System > Factory Reset. Follow the on-screen instructions to complete the reset.\n",
            "4. **Reset your STB to its original firmware**: If you're still experiencing issues, you can try resetting your STB to its original firmware. To do this, disconnect the power cable from the STB, then insert a needle or paper clip into the hole next to the USB connectors. Insert the power cable back in, and the STB will reboot to its original firmware.\n",
            "5. **Contact your IPTV provider**: If none of the above steps resolve the issue, contact your IPTV provider to see if there's an issue on their end. They may be able to assist you in resolving the problem.\n",
            "\n",
            "Remember to always back up your data before performing a factory reset, as it will erase all of your settings and data.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "# Instead of HuggingFacePipeline, call the pipeline directly\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the sentiment analysis pipeline\n",
        "sentiment_pipeline = pipeline(\"text-classification\", model=\"tabularisai/multilingual-sentiment-analysis\")\n",
        "\n",
        "# Create a LangChain prompt template (optional, you can skip this and call pipeline directly)\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=\"Classify the sentiment of the following text: {text}\"\n",
        ")\n",
        "\n",
        "# Create a function to use the pipeline for prediction\n",
        "def predict_sentiment(text):\n",
        "    result = sentiment_pipeline(text)[0]  # Get the prediction from the pipeline\n",
        "    return result['label']  # Extract the sentiment label\n",
        "\n",
        "# Example usage\n",
        "text = transcript.utterances[25].text\n",
        "# Instead of llm_chain.run, call predict_sentiment\n",
        "result = predict_sentiment(text)\n",
        "print(result)\n",
        "print(text)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AGoS56yEKrR",
        "outputId": "6be6ccec-1ef2-4be5-8a87-153355d5af93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutral\n",
            "Local import add manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx1q1jmMeGoN",
        "outputId": "3bb9668a-d937-4e77-cec1-90a27c586072",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.168.4.191:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://early-parts-hide.loca.lt\n",
            "/content/app.py:8: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "2025-04-23 23:29:20.496477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745450960.532885   10973 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745450960.543195   10973 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/content/app.py:11: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "/content/app.py:25: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding = SentenceTransformerEmbeddings(model_name=model_name) # use model_name keyword argument\n",
            "Device set to use cpu\n",
            "2025-04-23 23:29:33.781 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "/content/app.py:8: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "/content/app.py:11: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "Device set to use cpu\n",
            "/content/app.py:8: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "/content/app.py:11: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "Device set to use cpu\n",
            "/content/app.py:8: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "/content/app.py:11: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "Device set to use cpu\n",
            "/content/app.py:8: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "/content/app.py:11: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "Device set to use cpu\n",
            "/content/app.py:8: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "/content/app.py:11: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "Device set to use cpu\n",
            "/content/app.py:8: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "/content/app.py:11: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "Device set to use cpu\n",
            "/content/app.py:8: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "/content/app.py:11: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "Device set to use cpu\n",
            "/content/app.py:8: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "/content/app.py:11: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "Device set to use cpu\n",
            "/content/app.py:8: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "/content/app.py:11: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "Device set to use cpu\n",
            "/content/app.py:8: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "/content/app.py:11: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "Device set to use cpu\n",
            "/content/app.py:8: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "/content/app.py:11: LangChainDeprecationWarning: Importing SentenceTransformerEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import SentenceTransformerEmbeddings\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp=model.invoke(\"\"\"Perform sentiment ananlysis and\n",
        "Classify the following text on a scale of 1 to 10. 1 being bad and\n",
        "10 being the best. Give a 1 word answer: Pakistan is best\"\"\")\n",
        "print(temp.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUXO1mj7EkrC",
        "outputId": "cca92b3e-9bef-4cb4-a2f5-0a9334bbe011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A simple one!\n",
            "\n",
            "**Sentiment Analysis:** Positive\n",
            "\n",
            "**Sentiment Score:** 10\n",
            "\n",
            "**1-word answer:** EXCELLENT\n"
          ]
        }
      ]
    }
  ]
}